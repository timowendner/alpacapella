\section{Datasets}
\subsection{Annotation Dataset}
The annotation dataset contains royalty-free rap acapellas from Looperman. The website hosts a variety of free user-uploaded audio content. A lot of them are available under royalty-free licenses, making this suitable for research purposes. The Audio files were manually downloaded. The selection focuses on clear vocal content as well as varying tempo, voice and production, to ensure the diversity of the dataset. Beat annotations were made with Sonic Visualiser. Each acapella was analyzed and beats were manually marked at the beat position. This created ground truths for the model training and evaluation.

\textbf{Annotation Challenges:} The uploads on Looperman consisted of amateur rappers, leading to amateur quality of many recordings. Tempo inconsistencies and timing fluctuations were observes. Sometimes rappers "dance" around the beat, in order to make the track and flow more interesting. This leads to a unreliable onset information, as well as a challenging annotation process. The absence of clear onset information made precise beat placement difficult. The absence of drums, caused the visual feedback from the waveforms to be unreliable. Human error on the annotators side, contributed additional timing inaccuracies. Silent sections without vocal information caused uncertainties.

\textbf{Multi-Annotation Pipeline:} To address these issues, a processing pipeline was developed to combine multiple annotations. Each audio file was annotated 3 times independently. 
\begin{itemize}
    \item \textit{IBI Estimation:} For each raw annotation, the time difference between beats was used to estimate the inter beat interval (IBI). The estimate is the median of the time differences, with outliers removed. The IBI was capped between 0.3 and 1 seconds, representing 200 and 60 BPM, as this covers all the possible timings for rap.
    \item \textit{Missing Beat Interpolation:} If there was a space between two annotations that is larger than what the IBI suggests, then the missing beats were inserted. 
    \item \textit{Local Smoothing:} A smoothing algorithm addressed local timing issues. For each current beat \(t_i\), a window \(W\) of ±2.2 inter beat interval was investigated. Within this window, every beat \(t_j\) was moved with a step-size of the IBI-estimation, moving it closest to the current beat.
    \[ t'_i = \frac{1}{N} \sum_{t_j \in W} \left( t_j + IBI \cdot \operatorname{round} \left( \frac{t_i - t_j}{IBI} \right) \right) \]
    \item \textit{Voting Mechanism:} To combine the individual annotations, voting was used. Each time all annotations agree a beat is inside a window of 50ms, the average of the positions is accepted. Otherwise the position is rejected.
    \item \textit{Final Process:} The voting process creates gaps in the timeline. To solve this the missing beat interpolation is used from before. Finally the possible silence parts are filtered out, based on the raw annotations. If the position is close (±2 IBI) to a raw annotation, it is kept, but discarded otherwise.
\end{itemize}
