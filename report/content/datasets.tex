\section{Datasets}
\subsection{Annotation Dataset}
The annotation dataset contains royalty-free rap acapellas from Looperman\cite{looperman}. The website hosts a variety of free user-uploaded audio content. Many are available under royalty-free licenses, making this suitable for research purposes. The Audio files were manually downloaded. The selection focuses on clear vocal content as well as varying tempo, voice and production, to ensure the diversity of the dataset. Beat annotations were created using Sonic Visualiser~\cite{cannam2010}. Each acapella was analyzed and beats were manually marked at the beat position. This process generated ground truth data for the model training and evaluation.

\textbf{Multi-Annotation Pipeline:} To address these issues, a processing pipeline was developed to combine multiple annotations. Each audio file was annotated 3 times independently. 
\begin{itemize}
    \item \textit{IBI Estimation:} For each raw annotation, the time difference between beats was used to estimate the inter beat interval (IBI). The estimate is the mean of the time differences, with outliers removed. The IBI was capped between 0.3 and 1 seconds, representing 200 and 60 BPM, as this covers all the possible timings for rap.
    \item \textit{Missing Beat Interpolation:} If there was a space between two annotations that is larger than what the IBI suggests, then the missing beats were inserted. 
    \item \textit{Local Smoothing:} A smoothing algorithm addressed local timing issues. For each current beat \(t_i\), a window \(W\) of \(\pm 1.5\) inter beat interval was investigated. Within this window, every beat \(t_j\) was moved with a step-size of the IBI-estimation, moving it closest to the current beat.
    \[ t'_i = \frac{1}{N} \sum_{t_j \in W} \left( t_j + IBI \cdot \operatorname{round} \left( \frac{t_i - t_j}{IBI} \right) \right) \]
    \item \textit{Voting Mechanism:} To combine the individual annotations, voting was used. Each time all annotations agree a beat is inside a window of 70ms, the average of the positions is accepted. Otherwise the position is rejected.
    \item \textit{Final Process:} The voting process creates gaps in the timeline. To solve this the missing beat interpolation is used from before. Finally the possible silence parts are filtered out, based on the raw annotations. If the position is close (\(\pm 0.5 \) IBI) to a raw annotation, it is kept, but discarded otherwise.
\end{itemize}

The multi annotation pipeline has a certain percentage of real vs interpolated beats at the end. A beat is considered real if it originated from the consensus in the voting mechanism. This number is useful for the assessment of the annotation quality. The final dataset filters the annotations that are below 50\% real beats. There also seems to be some sort of lag, wether it is from the computer lag, or annotators personal bias. So the annotations are shifted 37ms backwards. Both choices are further discussed in the Discussions section.

The final dataset showed high diversity. The quality of the rappers varied significantly, ranging from amateur to semi-professional. The dataset contained multiple languages, including English, German, French, Portuguese. Recording environments varied considerably, with different microphones, recording qualities, some were dry, some used heavy post-processing. Some files contained just an isolated hook or verse, while others included the complete song.
The beat-detection seemed harder for slower beats, like old-school hip hop tracks, compared to faster, more melodic trap beats. The dataset consists of 110 annotations with accompanying wav files. This dataset is filtered down from 152 files (456 individual annotations). As shown in~\ref{tab:dataset_summary}, the final collection contains over 19,000 manually verified beats and roughly 2.5 hours of audio. The tempo distribution spans over a broad range of styles. The fast categories are featured dominantly, firstly because the modern style tends to faster beats, but also the annotation of the slower beats tends to be less accurate.

\begin{table}[h]
\centering
\caption{Dataset Summary and Tempo Distribution}
\label{tab:dataset_summary}
\begin{tabular}{lrr}
\hline
\textbf{Metric} & \textbf{Raw Dataset} & \textbf{Final Dataset} \\ \hline
Total Annotations & 456 & 110 \\
Total Duration (hh:mm:ss) & 04:10:29 & 02:39:50 \\
Total Annotated Beats & 74,020 & 19,115 \\ \hline
\textbf{BPM Distribution (Final)} & \textbf{Count} & \textbf{Percentage} \\ \hline
Slow ($<110$ BPM) & 27 & 24.5\% \\
Medium (110--140 BPM) & 35 & 31.8\% \\
Fast ($>140$ BPM) & 48 & 43.7\% \\ \hline
\end{tabular}
\end{table}

